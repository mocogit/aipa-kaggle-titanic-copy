{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# いつも使うやつ\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# pandasで全ての列を表示\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# 図をipython notebook内で表示\n",
    "%matplotlib inline\n",
    "\n",
    "# DeplicatedWarningを避けるため\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import sys\n",
    "sys.path.append('./lib/')\n",
    "\n",
    "# 交差検定をサクッとやるためのモジュールを読み込む\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 説明変数つくるための関数\n",
    "import feature_process_helper\n",
    "\n",
    "# submissionを書き込む関数\n",
    "import write_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをそれぞれ読み込む\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FamilySize'] = train.Parch + train.SibSp + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3つのクラスに分けたらどう？\n",
    "# pd.qcut(train_df['Fare'], 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     537\n",
       "2     161\n",
       "3     102\n",
       "4      29\n",
       "6      22\n",
       "5      15\n",
       "7      12\n",
       "11      7\n",
       "8       6\n",
       "Name: FamilySize, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['FamilySize'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 3.0]    800\n",
       "(3.0, 5.0]      44\n",
       "(5.0, 7.0]      34\n",
       "(9.0, 11.0]      7\n",
       "(7.0, 9.0]       6\n",
       "Name: FamilySize, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(train['FamilySize'], 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FamilySize\n",
       "(0.99, 3.5]    0.388750\n",
       "(3.5, 6.0]     0.409091\n",
       "(6.0, 8.5]     0.222222\n",
       "(8.5, 11.0]    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(pd.cut(train['FamilySize'], 4)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成したFamilySizeは4クラスでいけそう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 恐らく名字\n",
    "train['LastName'] = train['Name'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LastNameを合計する\n",
    "last_name_df = pd.DataFrame(train.groupby('LastName')[['LastName']].count()).rename(columns={'LastName': 'LastNameCount'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# それの2以上の値のレコードの生存率を調べたい\n",
    "_list = []\n",
    "for _last_name, _last_name_count in zip(last_name_df['LastName'], last_name_df['LastNameCount']):\n",
    "    if 2 < _last_name_count:\n",
    "        _list.append(_last_name)\n",
    "len(_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_has_family = train[train['LastName'].isin(_list)].groupby('Survived')['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_has_family = maybe_has_family.rename('MaybeHasFamily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe_has_not_family = train[~train['LastName'].isin(_list)].groupby('Survived')['Survived'].count()\n",
    "maybe_has_not_family = maybe_has_not_family.rename('MaybeNotHasFamily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaybeHasFamily</th>\n",
       "      <th>MaybeNotHasFamily</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MaybeHasFamily  MaybeNotHasFamily\n",
       "Survived                                   \n",
       "0                    128                421\n",
       "1                     63                279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([maybe_has_family, maybe_has_not_family], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x104edef98>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([maybe_has_family, maybe_has_not_family], axis=1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "なんか微妙だな・・・？？？  \n",
    "家族持ち（仮説:　名字が同じ人は家族かも）は生存する確率は低かったかも"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思ったけど、FamilySizeが1だったらダメじゃね？\n",
    "それもフィルタにしないといけないかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Navratil, Mr. Michel (\"Louis M Hoffman\")</td>\n",
       "      <td>male</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>230080</td>\n",
       "      <td>26.0</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>Navratil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Navratil, Master. Michel M</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>230080</td>\n",
       "      <td>26.0</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>Navratil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Navratil, Master. Edmond Roger</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>230080</td>\n",
       "      <td>26.0</td>\n",
       "      <td>F2</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>Navratil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                      Name  \\\n",
       "148          149         0       2  Navratil, Mr. Michel (\"Louis M Hoffman\")   \n",
       "193          194         1       2                Navratil, Master. Michel M   \n",
       "340          341         1       2            Navratil, Master. Edmond Roger   \n",
       "\n",
       "      Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  FamilySize  \\\n",
       "148  male  36.5      0      2  230080  26.0    F2        S           3   \n",
       "193  male   3.0      1      1  230080  26.0    F2        S           3   \n",
       "340  male   2.0      1      1  230080  26.0    F2        S           3   \n",
       "\n",
       "     LastName  \n",
       "148  Navratil  \n",
       "193  Navratil  \n",
       "340  Navratil  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['LastName'].str.contains('Navratil')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まだよくわかっていないが、こんな感じ\n",
    "\n",
    "* LastNameで調べるのは多分正しい\n",
    "    * FamilySizeと名字が同じ行数がほぼおなじ\n",
    "    * 違う場合もある。これはノイズになりそうなので、どうにか外さないといけないと思う\n",
    "    * FamilySizeとLastNameの整合性はあってそうだけど、数が足りない場合がある\n",
    "        * これはなに？　テストデータに分割しているから、一緒になったらわかるやつかね？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ここまでのやつをヘルパー関数に追加\n",
    "train, test = feature_process_helper.family_size_int(train, test)\n",
    "trian, test = feature_process_helper.add_last_name(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_family_train = train.copy()\n",
    "search_family_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.okubo/Documents/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "_test_concat = pd.concat([search_family_train, search_family_test.merge(submission_df, how='inner', on='PassengerId')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Allison',\n",
       " 'Andersson',\n",
       " 'Asplund',\n",
       " 'Baclini',\n",
       " 'Boulos',\n",
       " 'Bourke',\n",
       " 'Brown',\n",
       " 'Carter',\n",
       " 'Collyer',\n",
       " 'Davies',\n",
       " 'Elias',\n",
       " 'Flynn',\n",
       " 'Ford',\n",
       " 'Fortune',\n",
       " 'Goldsmith',\n",
       " 'Goodwin',\n",
       " 'Graham',\n",
       " 'Gustafsson',\n",
       " 'Hansen',\n",
       " 'Harper',\n",
       " 'Harris',\n",
       " 'Hart',\n",
       " 'Hickman',\n",
       " 'Hoyt',\n",
       " 'Jensen',\n",
       " 'Johansson',\n",
       " 'Johnson',\n",
       " 'Jussila',\n",
       " 'Kelly',\n",
       " 'Laroche',\n",
       " 'Lefebre',\n",
       " 'Meyer',\n",
       " 'Moran',\n",
       " 'Navratil',\n",
       " 'Newell',\n",
       " \"O'Brien\",\n",
       " 'Olsen',\n",
       " 'Palsson',\n",
       " 'Panula',\n",
       " 'Rice',\n",
       " 'Richards',\n",
       " 'Sage',\n",
       " 'Skoog',\n",
       " 'Smith',\n",
       " 'Taussig',\n",
       " 'Thayer',\n",
       " 'Van Impe',\n",
       " 'Vander Planke',\n",
       " 'West',\n",
       " 'Williams']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>LastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>Allison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>Allison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.55</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>Allison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "297          298         0       1   \n",
       "305          306         1       1   \n",
       "498          499         0       1   \n",
       "\n",
       "                                                Name     Sex    Age  SibSp  \\\n",
       "297                     Allison, Miss. Helen Loraine  female   2.00      1   \n",
       "305                   Allison, Master. Hudson Trevor    male   0.92      1   \n",
       "498  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female  25.00      1   \n",
       "\n",
       "     Parch  Ticket    Fare    Cabin Embarked  FamilySize LastName  \n",
       "297      2  113781  151.55  C22 C26        S           4  Allison  \n",
       "305      2  113781  151.55  C22 C26        S           4  Allison  \n",
       "498      2  113781  151.55  C22 C26        S           4  Allison  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_family_train[search_family_train['LastName'].str.contains('Allison')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2.00</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>151.55</td>\n",
       "      <td>Allison</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>2</td>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.92</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>151.55</td>\n",
       "      <td>Allison</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>2</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>25.00</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>151.55</td>\n",
       "      <td>Allison</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>2</td>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>30.00</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>151.55</td>\n",
       "      <td>Allison</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>2</td>\n",
       "      <td>1198</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age    Cabin Embarked  FamilySize    Fare LastName  \\\n",
       "297   2.00  C22 C26        S           4  151.55  Allison   \n",
       "305   0.92  C22 C26        S           4  151.55  Allison   \n",
       "498  25.00  C22 C26        S           4  151.55  Allison   \n",
       "306  30.00  C22 C26        S           4  151.55  Allison   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "297                     Allison, Miss. Helen Loraine      2          298   \n",
       "305                   Allison, Master. Hudson Trevor      2          306   \n",
       "498  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)      2          499   \n",
       "306             Allison, Mr. Hudson Joshua Creighton      2         1198   \n",
       "\n",
       "     Pclass     Sex  SibSp  Survived  Ticket  \n",
       "297       1  female      1         0  113781  \n",
       "305       1    male      1         1  113781  \n",
       "498       1  female      1         0  113781  \n",
       "306       1    male      1         0  113781  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test_concat[_test_concat['LastName'].str.contains('Allison')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "名字で紐付けるのは正解っぽいです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習させるためリセット！\n",
    "# データをそれぞれ読み込む\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "names() missing 1 required positional argument: 'submission_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b70722ba8295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_last_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mage_impute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcabin_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcabin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: names() missing 1 required positional argument: 'submission_df'"
     ]
    }
   ],
   "source": [
    "trian, test = feature_process_helper.add_last_name(train, test)\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.family_size_int(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size', 'LastName'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8c3fb594df9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                              n_jobs=-1)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=50,\n",
    "                             min_samples_split=16,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 2:], train.iloc[:, 1])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0a972a0b09e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# scikit-learnでは実装されているんだって\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 交差検定をサクッとやるためのモジュールを読み込む\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "# scikit-learnでは実装されているんだって\n",
    "# 交差検定をサクッとやるためのモジュールを読み込む\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(rf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4068eedcac0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m pd.concat((pd.DataFrame(train.iloc[:, 2:].columns, columns = ['variable']), \n\u001b[0;32m----> 2\u001b[0;31m            pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n\u001b[0m\u001b[1;32m      3\u001b[0m           axis = 1).sort_values(by='importance', ascending = False)\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mfeature_importances_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \"\"\"\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         all_importances = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.iloc[:, 2:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_write() got an unexpected keyword argument 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4ef6560389e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmission_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: _write() got an unexpected keyword argument 'train'"
     ]
    }
   ],
   "source": [
    "write_submission._write(model=rf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 0.79426 ....  \n",
    " クソがー！！＼（｀Д´#）ノ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流石にLastNameはやり過ぎと思うのでFamilySizeを追加\n",
    "# 学習させるためリセット！\n",
    "# データをそれぞれ読み込む\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "names() missing 1 required positional argument: 'submission_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-accd717b8aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mage_impute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membarked_impute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_process_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily_size_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket_Len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: names() missing 1 required positional argument: 'submission_df'"
     ]
    }
   ],
   "source": [
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.family_size_int(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Name_Title'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket', 'Cabin', 'SibSp', 'Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8c3fb594df9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                              n_jobs=-1)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/Documents/.venv/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=50,\n",
    "                             min_samples_split=16,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 2:], train.iloc[:, 1])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(rf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat((pd.DataFrame(train.iloc[:, 2:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission._write(model=rf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.77990  \n",
    "説明変数を減らしてもダメー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを複数使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, ensemble, svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = ensemble.RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "et_clf = ensemble.ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "gb_clf = ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "ada_clf = ensemble.AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "svm_clf = svm.LinearSVC(C=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_clf = ensemble.VotingClassifier(estimators=[('rf',rf_clf), ('et',et_clf), ('gbc',gb_clf), ('ada',ada_clf), ('svm',svm_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score using cross validation\n",
    "clf_list = [rf_clf, et_clf, gb_clf, ada_clf, svm_clf, e_clf]\n",
    "name_list = ['Random Forest', 'Extra Trees', 'Gradient Boosted', 'AdaBoost', 'Support Vector Machine', 'Ensemble']\n",
    "\n",
    "for clf, name in zip(clf_list,name_list) :\n",
    "    scores = model_selection.cross_val_score(clf, train.iloc[:, 2:], train.iloc[:, 1], cv=10)\n",
    "    print(\"Accuracy: %0.2f +/- %0.2f (%s 95%% CI)\" % (scores.mean(), scores.std()*2, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit ensemble classifier\n",
    "e_clf = e_clf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = e_clf.predict(test.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(e_clf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission._write(model=rf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.77990"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotを学ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図行列というものがあるらしい\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"iris\")\n",
    "sns.pairplot(df, hue=\"species\", size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをそれぞれ読み込む\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# タイタニックのデータで試す\n",
    "sns.pairplot(train[['Survived', 'Age', 'Sex_male', 'Sex_female']], hue=\"Survived\", size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[['Survived', 'Name_Len', 'Fare', 'Pclass_3', 'Pclass_2', 'Pclass_1']], hue='Survived', size=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# タイタニックのデータで試す\n",
    "sns.pairplot(train[['Survived', 'Embarked_S', 'Embarked_C', 'Embarked_Q']], hue='Survived', size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[['Survived', 'Fam_Size_Nuclear', 'Fam_Size_Solo', 'Fam_Size_Big']], hue='Survived', size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[['Survived', 'Cabin_Letter_n', 'Cabin_Letter_C', 'Cabin_Letter_E', 'Cabin_Letter_G', 'Cabin_Letter_D', 'Cabin_Letter_A', 'Cabin_Letter_B', 'Cabin_Letter_F']], hue='Survived', size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[['Survived', 'Name_Title_Mr.', 'Name_Title_Mrs.', 'Name_Title_Miss.', 'Name_Title_Master.', 'Name_Title_Rev.', 'Name_Title_Dr.', 'Name_Title_Ms.', 'Name_Title_Col.', 'Age']], hue='Survived', size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 20))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AgeClass'] = train['Age'] // 10 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___test = pd.concat([train, pd.get_dummies(train['AgeClass']).reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "___test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の尺度を揃える\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Fare'].isnull() == True, 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min-maxスケーリング\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "train.iloc[:, 2:] = mms.fit_transform(train.iloc[:, 2:])\n",
    "test.iloc[:, 1:] = mms.fit_transform(test.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param = {\n",
    "    \"C\": list(np.logspace(0, 4, 10))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=lr,\n",
    "                  param_grid=lr_param,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(gs, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])\n",
    "test.loc[test['Fare'].isnull() == True, 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "train.iloc[:, 2:] = stdsc.fit_transform(train.iloc[:, 2:])\n",
    "test.iloc[:, 1:] = stdsc.fit_transform(test.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param = {\n",
    "    \"C\": list(np.logspace(0, 4, 10))\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                  param_grid=lr_param,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(gs, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっとあがったかな？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1正則化による疎かな解\n",
    "lr_param = {\n",
    "    \"C\": list(np.logspace(0, 4, 10)),\n",
    "    'penalty': ['l1']\n",
    "}\n",
    "lr = LogisticRegression()\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                  param_grid=lr_param,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(gs, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN法を試す\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_param = {\n",
    "    'n_neighbors': [5, 10, 15, 20],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "gs = GridSearchCV(estimator=knn,\n",
    "                  param_grid=knn_param,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(gs, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰とKNNをアンサンブル\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])\n",
    "test.loc[test['Fare'].isnull() == True, 'Fare'] = 0\n",
    "\n",
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "train.iloc[:, 2:] = stdsc.fit_transform(train.iloc[:, 2:])\n",
    "test.iloc[:, 1:] = stdsc.fit_transform(test.iloc[:, 1:])\n",
    "\n",
    "lr_param = {\n",
    "    \"C\": list(np.logspace(0, 4, 10))\n",
    "}\n",
    "\n",
    "knn_param = {\n",
    "    'n_neighbors': [5, 10, 15, 20],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import  RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params.update({\"knn__\" + k: v for k, v in knn_param.items()})\n",
    "params.update({\"lr__\" + k: v for k, v in lr_param.items()})\n",
    "\n",
    "eclf = VotingClassifier(estimators=[(\"knn\", knn), (\"lr\", lr)],voting=\"soft\")\n",
    "clf = RandomizedSearchCV(eclf,\n",
    "    param_distributions=params,\n",
    "    cv=5,\n",
    "    n_iter=80,\n",
    "    n_jobs=-1,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param = {\n",
    "    \"C\": 1.0\n",
    "}\n",
    "\n",
    "knn_param = {\n",
    "    'n_neighbors': 5,\n",
    "    'p': 1\n",
    "}\n",
    "eclf = VotingClassifier(estimators=[(\"knn\", knn), (\"lr\", lr)],voting=\"soft\")\n",
    "eclf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(eclf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっとはあがった？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレストで特徴選択する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主成分分析してみる\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pca = pca.fit_transform(train.iloc[:, 2:])\n",
    "test_pca = pca.transform(test.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(train_pca, train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(train_pca, train.iloc[:, 1]))\n",
    "print(lr.score(test_pca, submission_df['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(lr, train_pca, train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    #setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    # 最小値, 最大値からエリアの領域を割り出す\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    # resolutionの間隔で区切った領域を定義\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                            np.arange(x2_min, x2_max, resolution))\n",
    "    # print(xx1.shape)\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot all samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_decision_regions(train_pca, train.iloc[:, 1], classifier=lr)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "from sklearn.lda import LDA\n",
    "lda = LDA(n_components=3)\n",
    "train_lda = lda.fit_transform(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_pca, train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(train_pca, train.iloc[:, 1]))\n",
    "print(lr.score(test_pca, submission_df['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(lr, train_pca, train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の尺度を揃える\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインを使う\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe_lr = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('pca', PCA(n_components=2)),\n",
    "        ('clf', LogisticRegression(random_state=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(pipe_lr, train_pca, train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1))\n",
    "])\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{\n",
    "    'clf__C': param_range,\n",
    "    'clf__kernel': ['linear'],\n",
    "    'clf__C': param_range,\n",
    "    'clf__gamma': param_range,\n",
    "    'clf__kernel': ['rbf']\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                 param_grid=param_grid,\n",
    "                 scoring='accuracy',\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適な値でやり直す\n",
    "pipe_svc = Pipeline([\n",
    "    ('scl', StandardScaler()),\n",
    "    ('clf', SVC(random_state=1, C=1.0, gamma=0.01, kernel='rbf'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(pipe_svc, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelineを覚えたところで、knn、LR, RFを使って、Randamizeのあとにアンサンブル\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "submission_df = pd.read_csv('./data/gender_submission.csv')\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "train, test = feature_process_helper.names(train, test)\n",
    "train, test = feature_process_helper.age_impute(train, test)\n",
    "train, test = feature_process_helper.cabin_num(train, test)\n",
    "train, test = feature_process_helper.cabin(train, test)\n",
    "train, test = feature_process_helper.embarked_impute(train, test)\n",
    "train, test = feature_process_helper.fam_size(train, test)\n",
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "test['Ticket_Len'] = test['Ticket'].apply(lambda x: len(x))\n",
    "train, test = feature_process_helper.dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = feature_process_helper.drop(train, test, bye = ['Ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダミー変数の１つを削除する\n",
    "for _data in [train, test]:\n",
    "    for i in ['Cabin_num_(65.667, 148]', 'Pclass_3', 'Sex_male', 'Embarked_S', 'Cabin_Letter_n', 'Name_Title_Mr.', 'Fam_Size_Nuclear']:\n",
    "        del _data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パイプラインを使う\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmだけRandamizeにあてるのが難しかったので別個やる\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe_svm = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('svc', SVC(random_state=1))\n",
    "])\n",
    "\n",
    "svm_param = [\n",
    "    {'svc__C': [1, 10, 100, 1000], 'svc__kernel': ['linear']},\n",
    "    {'svc__C': [1, 10, 100, 1000], 'svc__kernel': ['rbf'], 'svc__gamma': [0.001, 0.0001]},\n",
    "    {'svc__C': [1, 10, 100, 1000], 'svc__kernel': ['poly'], 'svc__degree': [2, 3, 4], 'svc__gamma': [0.001, 0.0001]},\n",
    "    {'svc__C': [1, 10, 100, 1000], 'svc__kernel': ['sigmoid'], 'svc__gamma': [0.001, 0.0001]}\n",
    "]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svm,\n",
    "                   param_grid=svm_param,\n",
    "                   cv=10,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Fare'].isnull() == True, 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 40分ぐらい？恐ろしい...\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰\n",
    "pipe_lr = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('lr', LogisticRegression(random_state=1))\n",
    "])\n",
    "lr_param = [{\n",
    "    \"lr__C\": np.logspace(0, 4, 10)\n",
    "}]\n",
    "gs = GridSearchCV(estimator=pipe_lr,\n",
    "                   param_grid=lr_param,\n",
    "                   cv=10,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレスト\n",
    "pipe_rf = Pipeline([\n",
    "        ('rf', RandomForestClassifier())\n",
    "])\n",
    "rf_param = [{\n",
    "    \"rf__n_estimators\": [5, 10, 50, 100, 300],\n",
    "    \"rf__max_features\": [3, 5, 10, 15, 20],\n",
    "    \"rf__min_samples_split\": [3, 5, 10, 20],\n",
    "    \"rf__max_depth\": [3, 5, 10, 20]\n",
    "}]\n",
    "gs = GridSearchCV(estimator=pipe_rf,\n",
    "                   param_grid=rf_param,\n",
    "                   cv=10,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "pipe_knn = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "])\n",
    "knn_param = [{\n",
    "    'knn__n_neighbors': [5, 10, 15, 20],\n",
    "    'knn__p': [1, 2]\n",
    "}]\n",
    "gs = GridSearchCV(estimator=pipe_knn,\n",
    "                   param_grid=knn_param,\n",
    "                   cv=10,\n",
    "                   scoring='accuracy',\n",
    "                   n_jobs=-1)\n",
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('lr', LogisticRegression(C = 21.544346900318832))\n",
    "])\n",
    "pipe_svm = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('svm', SVC(C = 100, gamma = 0.001, kernel = 'rbf', probability = True))\n",
    "])\n",
    "pipe_knn = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors = 10, p = 1))\n",
    "])\n",
    "pipe_rf = Pipeline([\n",
    "        ('rf', RandomForestClassifier(max_depth = 5, \n",
    "                                      max_features =20,\n",
    "                                      min_samples_split = 5,\n",
    "                                      n_estimators = 10))\n",
    "])\n",
    "\n",
    "lr_param = {\n",
    "    # 'lr__scl': ['test'],\n",
    "    \"lr__C\": list(np.logspace(0, 4, 10))\n",
    "}\n",
    "rf_param = {\n",
    "    \"rf__n_estimators\": [5, 10, 50, 100, 300],\n",
    "    \"rf__max_features\": [3, 5, 10, 15, 20],\n",
    "    \"rf__min_samples_split\": [3, 5, 10, 20],\n",
    "    \"rf__max_depth\": [3, 5, 10, 20]\n",
    "}\n",
    "knn_param = {\n",
    "    'n_neighbors': [5, 10, 15, 20],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "svm_param = {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "params = {}\n",
    "params.update(lr_param)\n",
    "# params.update(rf_param)\n",
    "# params.update({\"lr__\" + k: v for k, v in lr_param.items()})\n",
    "# params.update({\"rf__\" + k: v for k, v in rf_param.items()})\n",
    "# params.update({\"svm__\" + k: v for k, v in svm_param.items()})\n",
    "# params.update({\"knn__\" + k: v for k, v in knn_param.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('lr', pipe_lr), ('svm', pipe_svm), ('knn', pipe_knn), ('rf', pipe_rf)], voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomizedSearchCV(eclf,\n",
    "#     param_distributions=params,\n",
    "#     cv=5,\n",
    "#     n_iter=5,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eclf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Fare'].isnull() == True, 'Fare'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(eclf.score(train.iloc[:, 2:], train.iloc[:, 1]))\n",
    "print(eclf.score(test.iloc[:, 1:], submission_df['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(eclf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission._write(model=eclf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最初: 0.79426  \n",
    "* ダミー変数 - 1: 0.78947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\"   : [\"gini\", \"entropy\"],\n",
    "             \"min_samples_leaf\" : [1,5,10],\n",
    "             \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "             \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                criterion='gini',\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=4,\n",
    "                                n_estimators=100,\n",
    "                                n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(rf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission._write(model=rf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3回目: 0.78469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_rf_important = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_rf_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランダムフォレストの結果で良い変数だけ残す\n",
    "for _data in [train, test]:\n",
    "    for i in ['Name_Title_Dr.',\n",
    "              'Cabin_num_(65.667, 148]',\n",
    "              'Pclass_2',\n",
    "              'Sex_male',\n",
    "              'Embarked_S',\n",
    "              'Cabin_Letter_n',\n",
    "              'Name_Title_Mr.',\n",
    "              'Fam_Size_Nuclear',\n",
    "              'Name_Title_Ms.',\n",
    "              'Cabin_Letter_C',\n",
    "              'Name_Title_Col.',\n",
    "              'Cabin_num_[2, 28.667]',\n",
    "              'Cabin_Letter_E',\n",
    "              'Age_Null_Flag',\n",
    "              'Cabin_Letter_D',\n",
    "              'Cabin_num_(28.667, 65.667]',\n",
    "              'Cabin_Letter_B',\n",
    "              'Name_Title_Master.',\n",
    "              'Cabin_Letter_G',\n",
    "              'Cabin_Letter_F',\n",
    "              'Name_Title_Rev.',\n",
    "              'Cabin_Letter_A',\n",
    "              'Name_Title_Mrs.',\n",
    "              'Name_Title_Miss.',\n",
    "              'Fam_Size_Big',\n",
    "              'Fam_Size_Solo']:\n",
    "        del _data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\"   : [\"gini\", \"entropy\"],\n",
    "             \"min_samples_leaf\" : [1,5,10],\n",
    "             \"min_samples_split\" : [2, 4, 10, 12, 16],\n",
    "             \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                criterion='gini',\n",
    "                                min_samples_leaf=1,\n",
    "                                min_samples_split=2,\n",
    "                                n_estimators=100,\n",
    "                                n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 2:], train.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "cv_scores = cross_val_score(rf, train.iloc[:, 2:], train.iloc[:, 1], cv=10, n_jobs=-1)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rf_important = pd.concat((pd.DataFrame(train.iloc[:, 2:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rf_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission._write(model=rf, train=train, test=test, submission_df=submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下がった・・・？  \n",
    "0.75120"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
